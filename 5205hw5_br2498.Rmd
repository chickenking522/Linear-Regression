---
title: "STAT GR5205 – Section 005 HW 5"
author: "Bo Rong br2498"
date: "Nov. 6th, 2016"
output: pdf_document
---

```{r}
#1.
#(a)
filename <- "~/Downloads/patient_satisfaction.txt"
ps<- read.table(file=filename, header=T)
par(mfrow=c(1,3))
boxplot(ps$Age, main="Boxplot of Age")
boxplot(ps$Severity, main="Boxplot of Severity")
boxplot(ps$Anxiety, main="Boxplot of Anxiety")
#There is a outlier for severity.
```

```{r}
#(b)
pairs(ps)
#Each of Age,Severity and Anxiety is negatively related to Y . The three predictor variables are all positively related to each other.
```


```{r}
#(C)
fit<-lm(Y~Age+Severity+Anxiety,data=ps)
fit
#Yhat = 158.491 -1.142*Age – 0.442*Severity – 13.470*Anxiety, In this model, b2 = -0.442, which indicates that for every additional unit of illness severity, patients’ satisfaction decreases 0.442 unit when Age and Anxiety are fixed.


```

```{r}
#(d)
x1 <-ps$Age
x2<-ps$Severity
x3<-ps$Anxiety
Y<-ps$Y
fitY.13 <- lm(Y ~ x1+x3, data=ps)
fit2.13 <- lm(x2 ~ x1+x3, data=ps)
plot(resid(fitY.13) ~ resid(fit2.13),
ylab="Y unexplained by (X1, X3)",
xlab="X2 unexplained by (X1, X3)")
lines(lowess(resid(fitY.13) ~ resid(fit2.13)))
abline(lm(resid(fitY.13) ~ resid(fit2.13)), lty=2)
#The slop of the relation between satisfaction unexplained by severity and severity unexplained by Age and Anxiety is non-zero. This means introducing the variable severity helps reduce total variation of the observations.

coef(lm(resid(fitY.13) ~ resid(fit2.13)))
#The slope is also -0.442, which is consistent with part(c).
```

```{r}
#(e)
par(mfrow=c(2,2))
plot(resid(fit)~fitted(fit),xlab="Fitted values",ylab="Residuals")
lines(lowess(resid(fit) ~ fitted(fit)))
plot(resid(fit) ~ x1, xlab="Age",ylab="Residuals")
lines(lowess(resid(fit) ~ x1))
plot(resid(fit) ~ x2,xlab="Severity", ylab="Residuals")
lines(lowess(resid(fit) ~ x2))
plot(resid(fit) ~ x3, xlab="Anxiety",ylab="Residuals")
lines(lowess(resid(fit) ~ x3))
#We don’t see violation against assumptions.

```


```{r}
#(f)
qqnorm(resid(fit))
#The plot is close to a straight line, so error terms appears to be reasonable.
```

```{r}
#2.
#(a)
#H0:beta1=beta2=beta3=0
#Ha:not all betai=0
fit0<-lm(Y~1, data=ps)
fit123 <- lm(Y ~ x1 + x2 + x3)
anova(fit0, fit123)
#F=30.052,and the p-value is 1.542e-10, which is almost zero,So we reject H0.


```

```{r}
#(b)
alpha <-0.10 
g <- 3
1-alpha/g
confint(fit123, level=1-alpha/g)[-1,]
#The 90% confidence intervals: -1.614248 <= beta1 <= -0.6689755, -1.524510 <= beta2 <= 0.6405013 
#and -29.092028 <= beta3 <= 2.1517012.
```

```{r}
#(c)
summary(fit123)$r.squared
#Thus 68% of all the Y’s explained by x1, x2 and x3.

```


```{r}
#(d)
x123 <-data.frame(x1=35, x2=45, x3=2.2)
predict(fit123, newdata=x123, interval="confidence")
#The 95% confidence interval:(63.63288,74.38769)

```

```{r}
#(e)
predict(fit123, newdata=x123, interval="prediction")
#The 95% confident interval:(48.01224,90.00833)

```

```{r}
#3.
#(a)
fit213<-lm(Y~x2 + x1 + x3)
anova(fit213)
```

```{r}
#(b)
#H0 :beta3 =0, Ha:beta3!=0
summary(fit213)
#t=-1.897,P-value=0.0647. And F=3.5997 ,P-value=0.0647. Thus F=3.5997= (-1.897)^2 = t^2.So these two tests are consistent.The p-value=0.0.674, which is the probability of obtaining a result that is beta3 =0.  
```

```{r}
#(c)
#H0:beta2 =beta3=0, Ha=not all beta2 or beta3 =0.
fit1 <- lm(Y ~ x1)
anova(fit1, fit123)
#F=4.1768,P-value=0.02216,If x2 and x3 don't provide any other information rather than x1 contained, 
#the probability would be .02216.
```

```{r}
#4.
#(a)
fit12 <- lm(Y ~ x1+x2)
fit123 <- update(fit12, ~ . + x3)
summary(fit12)$coef
#The corresponding coefficient of x2 in fit12 has greater absolute value than in fit. 
#This indicates that without introducing x3, part of the reduction of variance that can be taken by x3 is taken by x1 an x2.

```


```{r}
#(b)
fit31 <- lm(Y~x3+x1)
anova(fit1)
anova(fit31)
#SSR(X1|X3) =3483.9<8275.4=SSR(X1)
fit2 <-lm(Y ~ x2)
fit32 <-lm(Y~x3+x2)
anova(fit2)
anova(fit32)
#SSR(X2|X3)=708.0<4860.3=SSR(X2)
```

```{r}
#(c)
cor(x1,x3)
cor(x2,x3)
#We can see that Anxiety has positive relationship with both Age and Severity. Thus some of the predictive power of Age is already contained in Anxiety .
```


```{r}
#5.
#(a)i. 
plot(Y ~ x1,xlab="Age")
#ii.
fit2 <- lm(Y ~ x2)
fit1_2 <- lm(x1 ~ x2)
plot(resid(fit2) ~ resid(fit1_2),ylab="Y unexplained by Severity",xlab="Age unexplained by Severity")

#iii.
fit23 <- lm(Y ~ x2 + x3)
fit1_23 <- lm(x1 ~ x2+x3)
plot(resid(fit23) ~ resid(fit1_23),ylab="Y unexplained by (Severity,Anxiety)",xlab="Age unexplained by (Severity,Anxiety)")

```


```{r}
#(b)
summary(lm(Y ~ x1))$r.squared
#R^2(Y1)=0.6189843
summary(lm(resid(fit2) ~ resid(fit1_2)))$r.squared
#R^2(Y1|2)=0.4578709
summary(lm(resid(fit23) ~ resid(fit1_23)))$r.squared
#R^2(Y1|23)=0.4021102
#So,R^2(Y1)=0.6189843 > R^2(Y1|2)=0.46 > R^2(Y1|23)=0.4021102
#The degree of marginal linear association between Y and X1 is reduced by adjusting for X2, 
#and reduced by adjusting for X2 and X3. This was apparent in the scatterplots of part(a).


```





















